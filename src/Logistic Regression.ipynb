{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if not './' in sys.path:\n",
    "    sys.path.append('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from envs.stocks_env_multiaction import Stocks_env\n",
    "from datasets import nyse\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = nyse.load_data('../data/')\n",
    "data, _, _ = nyse.load_data_with_industry('../data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_data = data.drop([\"symbol\"], axis=1)\n",
    "scaler = preprocessing.StandardScaler().fit(fit_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper params:\n",
    "input_shape      = np.shape(data)[1]-1\n",
    "lr               = 1e-3\n",
    "seed             = 42\n",
    "epochs           = 8\n",
    "batch_size       = 256\n",
    "\n",
    "# log\n",
    "save_directory = 'results/logreg/'\n",
    "date = datetime.now().strftime(\"%Y_%m_%d-%H:%M:%S\")\n",
    "identifier = \"logreg-\" + date\n",
    "train_summary_writer = tf.summary.create_file_writer('results/summaries/logreg/train/' + identifier)\n",
    "test_summary_writer = tf.summary.create_file_writer('results/summaries/logreg/test/' + identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean('train_loss', dtype=tf.float32)\n",
    "train_accuracy = tf.keras.metrics.BinaryAccuracy('train_accuracy')\n",
    "test_loss = tf.keras.metrics.Mean('test_loss', dtype=tf.float32)\n",
    "test_accuracy = tf.keras.metrics.BinaryAccuracy('test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format data\n",
    "symbols = data['symbol'].unique().tolist()\n",
    "X = []\n",
    "Y = []\n",
    "for sym in symbols:\n",
    "    sym_data = scaler.transform(data.loc[data.symbol==sym].drop([\"symbol\"], axis=1))\n",
    "    for i in range(len(sym_data)-1):\n",
    "        X.append(sym_data[i])\n",
    "        Y.append(1 if (sym_data[i][1]<sym_data[i+1][1]) else 0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=seed)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "\n",
    "train_dataset = train_dataset.shuffle(60000).batch(batch_size)\n",
    "test_dataset = test_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "model = tf.keras.Sequential(tf.keras.layers.Dense(1, input_shape=(input_shape,), activation='sigmoid'))\n",
    "optimizer = tf.keras.optimizers.Adam(lr)\n",
    "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, optimizer, x_train, y_train):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(x_train, training=True)\n",
    "        loss = loss_object(y_train, predictions)\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(y_train, predictions)\n",
    "\n",
    "def test_step(model, x_test, y_test):\n",
    "    predictions = model(x_test)\n",
    "    loss = loss_object(y_test, predictions)\n",
    "\n",
    "    test_loss(loss)\n",
    "    test_accuracy(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.7085803747177124, Accuracy: 48.9560546875, Test Loss: 0.7048982977867126, Test Accuracy: 48.888370513916016\n",
      "Epoch 2, Loss: 0.7012513279914856, Accuracy: 48.67889404296875, Test Loss: 0.7000302672386169, Test Accuracy: 48.74544906616211\n",
      "Epoch 3, Loss: 0.697316586971283, Accuracy: 48.579349517822266, Test Loss: 0.6965746283531189, Test Accuracy: 48.73939895629883\n",
      "Epoch 4, Loss: 0.6949887275695801, Accuracy: 48.525020599365234, Test Loss: 0.6950132846832275, Test Accuracy: 48.71697235107422\n",
      "Epoch 5, Loss: 0.694089949131012, Accuracy: 48.47576141357422, Test Loss: 0.6942412257194519, Test Accuracy: 48.70900344848633\n",
      "Epoch 6, Loss: 0.6930350065231323, Accuracy: 48.45016860961914, Test Loss: 0.6930944323539734, Test Accuracy: 48.70433044433594\n",
      "Epoch 7, Loss: 0.6926165223121643, Accuracy: 48.439414978027344, Test Loss: 0.69289231300354, Test Accuracy: 48.70433044433594\n",
      "Epoch 8, Loss: 0.6925498247146606, Accuracy: 48.441097259521484, Test Loss: 0.6928231120109558, Test Accuracy: 48.70433044433594\n"
     ]
    }
   ],
   "source": [
    "test_total_profits = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    for (x_train, y_train) in train_dataset:\n",
    "        train_step(model, optimizer, x_train, y_train)\n",
    "    with train_summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', train_loss.result(), step=epoch)\n",
    "        tf.summary.scalar('accuracy', train_accuracy.result(), step=epoch)\n",
    "\n",
    "    for (x_test, y_test) in test_dataset:\n",
    "        test_step(model, x_test, y_test)\n",
    "    with test_summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', test_loss.result(), step=epoch)\n",
    "        tf.summary.scalar('accuracy', test_accuracy.result(), step=epoch)\n",
    "\n",
    "    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "    print (template.format(epoch+1,\n",
    "            train_loss.result(), \n",
    "            train_accuracy.result()*100,\n",
    "            test_loss.result(), \n",
    "            test_accuracy.result()*100))\n",
    "\n",
    "    # Reset metrics every epoch\n",
    "    train_loss.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.15989657, 'open'),\n",
       " (-0.19772957, 'close'),\n",
       " (0.11944062, 'low'),\n",
       " (-0.07273539, 'high'),\n",
       " (-0.05442702, 'volume'),\n",
       " (0.08966919, 'Accounts Payable'),\n",
       " (0.021010576, 'Accounts Receivable'),\n",
       " (-0.027171114, \"Add'l income/expense items\"),\n",
       " (0.01937542, 'After Tax ROE'),\n",
       " (0.22196895, 'Capital Expenditures'),\n",
       " (0.02117831, 'Capital Surplus'),\n",
       " (-0.062394377, 'Cash Ratio'),\n",
       " (-0.1270617, 'Cash and Cash Equivalents'),\n",
       " (0.047790807, 'Changes in Inventories'),\n",
       " (0.07777014, 'Common Stocks'),\n",
       " (0.106798984, 'Cost of Revenue'),\n",
       " (-0.021594241, 'Current Ratio'),\n",
       " (-0.015595697, 'Deferred Asset Charges'),\n",
       " (-0.031983275, 'Deferred Liability Charges'),\n",
       " (0.1295437, 'Depreciation'),\n",
       " (-0.19305989, 'Earnings Before Interest and Tax'),\n",
       " (-0.10321899, 'Earnings Before Tax'),\n",
       " (0.0041140895, 'Effect of Exchange Rate'),\n",
       " (0.23839177, 'Equity Earnings/Loss Unconsolidated Subsidiary'),\n",
       " (-0.20699006, 'Fixed Assets'),\n",
       " (0.018536765, 'Goodwill'),\n",
       " (0.03508943, 'Gross Margin'),\n",
       " (0.10541249, 'Gross Profit'),\n",
       " (0.19734253, 'Income Tax'),\n",
       " (0.13355829, 'Intangible Assets'),\n",
       " (-0.17602208, 'Interest Expense'),\n",
       " (-0.0025003892, 'Inventory'),\n",
       " (-0.081173904, 'Investments'),\n",
       " (0.028858133, 'Liabilities'),\n",
       " (-0.015410017, 'Long-Term Debt'),\n",
       " (-0.059088428, 'Long-Term Investments'),\n",
       " (-0.060415223, 'Minority Interest'),\n",
       " (0.052735303, 'Misc. Stocks'),\n",
       " (-0.16270235, 'Net Borrowings'),\n",
       " (0.30459827, 'Net Cash Flow'),\n",
       " (-0.051255636, 'Net Cash Flow-Operating'),\n",
       " (-0.17853276, 'Net Cash Flows-Financing'),\n",
       " (-0.012475527, 'Net Cash Flows-Investing'),\n",
       " (-0.007237089, 'Net Income'),\n",
       " (0.030531632, 'Net Income Adjustments'),\n",
       " (-0.044338573, 'Net Income Applicable to Common Shareholders'),\n",
       " (-0.019390859, 'Net Income-Cont. Operations'),\n",
       " (-0.042641692, 'Net Receivables'),\n",
       " (-0.19151591, 'Non-Recurring Items'),\n",
       " (0.2126374, 'Operating Income'),\n",
       " (-0.115024894, 'Operating Margin'),\n",
       " (-0.12695658, 'Other Assets'),\n",
       " (-0.11095659, 'Other Current Assets'),\n",
       " (-0.21254101, 'Other Current Liabilities'),\n",
       " (0.08447041, 'Other Equity'),\n",
       " (0.017648121, 'Other Financing Activities'),\n",
       " (-0.08386561, 'Other Investing Activities'),\n",
       " (0.10737695, 'Other Liabilities'),\n",
       " (-0.09191378, 'Other Operating Activities'),\n",
       " (-0.057637196, 'Other Operating Items'),\n",
       " (-0.023080353, 'Pre-Tax Margin'),\n",
       " (-0.048542995, 'Pre-Tax ROE'),\n",
       " (0.13798867, 'Profit Margin'),\n",
       " (0.02022573, 'Quick Ratio'),\n",
       " (-0.05218117, 'Research and Development'),\n",
       " (-0.32454595, 'Retained Earnings'),\n",
       " (-0.01603744, 'Sale and Purchase of Stock'),\n",
       " (-0.07250982, 'Sales, General and Admin.'),\n",
       " (0.02872207, 'Short-Term Debt / Current Portion of Long-Term Debt'),\n",
       " (0.29647112, 'Short-Term Investments'),\n",
       " (-0.0073608444, 'Total Assets'),\n",
       " (-0.07006701, 'Total Current Assets'),\n",
       " (-0.014121261, 'Total Current Liabilities'),\n",
       " (0.011505632, 'Total Equity'),\n",
       " (0.16001107, 'Total Liabilities'),\n",
       " (0.010682229, 'Total Liabilities & Equity'),\n",
       " (0.0726818, 'Total Revenue'),\n",
       " (-0.07457304, 'Treasury Stock'),\n",
       " (0.21740438, 'Earnings Per Share'),\n",
       " (-0.2218255, 'Estimated Shares Outstanding')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = data.columns[1:].tolist()\n",
    "weights = model.layers[0].get_weights()\n",
    "[(weights[0][i][0], columns[i]) for i in range(len(columns))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 1\n",
    "run_lenght = 10\n",
    "initial_money = 100\n",
    "train_test_ratio = 0.2\n",
    "env = Stocks_env(data, window_size, run_lenght, batch_size=batch_size, train_test_ratio = train_test_ratio,\n",
    "                 test_seed=seed, initial_money=initial_money)\n",
    "batch_size  = len(env.get_test_symbols())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_env(record_days=False):\n",
    "    state = env.reset(training=False, batch_size=batch_size, run_lenght=run_lenght, initial_money=initial_money)\n",
    "    state = np.reshape(state, (batch_size, len(columns)))\n",
    "    done = False\n",
    "    operation_array = []\n",
    "    days_array = []\n",
    "    rewards_array = []\n",
    "    total_profit = np.zeros(batch_size)\n",
    "    while not done:\n",
    "        actions = []\n",
    "        for result in model(state):\n",
    "            buy = 1 if result>0 else 0 \n",
    "            sell = 1 if result<0 else 0\n",
    "            actions += [[buy, sell]]\n",
    "        next_state, reward, done, operations, day, profit = env.step(actions)\n",
    "        state = next_state\n",
    "        if record_days:\n",
    "            operation_array.append(np.array(operations))\n",
    "            days_array.append(np.array(day))\n",
    "            rewards_array.append(np.array(reward))\n",
    "        mean_test_reward(np.array(reward))\n",
    "        total_profit += profit\n",
    "    total_profit = total_profit/initial_money\n",
    "    return operation_array, days_array, rewards_array, total_profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "save_directory = 'results/test-all/'\n",
    "date = datetime.now().strftime(\"%Y_%m_%d-%H:%M:%S\")\n",
    "identifier = \"logreg-\" + date\n",
    "test_summary_writer = tf.summary.create_file_writer('results/summaries/test/' + identifier)\n",
    "mean_test_reward = tf.keras.metrics.Mean(name='mean_test_reward')\n",
    "\n",
    "repeat = 100\n",
    "\n",
    "test_total_profits = []\n",
    "\n",
    "for i in range(repeat):\n",
    "\n",
    "    print(i)\n",
    "    operation_array, days_array, rewards_array, test_total_profit = test_env(record_days=True)\n",
    "    test_total_profits.append(test_total_profit)\n",
    "\n",
    "    with test_summary_writer.as_default():\n",
    "        tf.summary.scalar('mean_test_reward', mean_test_reward.result(), step=i)\n",
    "\n",
    "    # serialize weights to HDF5\n",
    "    if not os.path.exists(save_directory):\n",
    "        os.makedirs(save_directory)\n",
    "    if not os.path.exists(save_directory+'operations/'):\n",
    "        os.makedirs(save_directory+'operations/')\n",
    "    if not os.path.exists(save_directory+'endingdays/'):\n",
    "        os.makedirs(save_directory+'endingdays/')\n",
    "    if not os.path.exists(save_directory+'rewards/'):\n",
    "        os.makedirs(save_directory+'rewards/')\n",
    "    if not os.path.exists(save_directory+'profits/'):\n",
    "        os.makedirs(save_directory+'profits/')\n",
    "    pd.DataFrame(operation_array).to_csv(save_directory+\"operations/{}-iteration{}.csv\".format(identifier, i), \n",
    "                                         header=env.get_current_symbols(), index=None)\n",
    "    pd.DataFrame(days_array).to_csv(save_directory+\"endingdays/{}-iteration{}.csv\".format(identifier, i), \n",
    "                                         header=env.get_current_symbols(), index=None)\n",
    "    pd.DataFrame(rewards_array).to_csv(save_directory+\"rewards/{}-iteration{}.csv\".format(identifier, i), \n",
    "                                         header=env.get_current_symbols(), index=None)\n",
    "    pd.DataFrame(test_total_profits).to_csv(save_directory+\"profits/{}.csv\".format(identifier),\n",
    "                                            index=None)\n",
    "    mean_test_reward.reset_states()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
