{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if not './' in sys.path:\n",
    "    sys.path.append('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from envs.stocks_env_multiaction import Stocks_env\n",
    "from datasets import nyse\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = nyse.load_data('../data/')\n",
    "data, _, _ = nyse.load_data_with_industry('../data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_data = data.drop([\"symbol\"], axis=1)\n",
    "scaler = preprocessing.StandardScaler().fit(fit_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper params:\n",
    "input_shape      = np.shape(data)[1]-1\n",
    "lr               = 1e-3\n",
    "seed             = 42\n",
    "epochs           = 8\n",
    "batch_size       = 256\n",
    "\n",
    "# log\n",
    "save_directory = 'results/logreg/'\n",
    "date = datetime.now().strftime(\"%Y_%m_%d-%H:%M:%S\")\n",
    "identifier = \"logreg-\" + date\n",
    "train_summary_writer = tf.summary.create_file_writer('results/summaries/logreg/train/' + identifier)\n",
    "test_summary_writer = tf.summary.create_file_writer('results/summaries/logreg/test/' + identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean('train_loss', dtype=tf.float32)\n",
    "train_accuracy = tf.keras.metrics.BinaryAccuracy('train_accuracy')\n",
    "test_loss = tf.keras.metrics.Mean('test_loss', dtype=tf.float32)\n",
    "test_accuracy = tf.keras.metrics.BinaryAccuracy('test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format data\n",
    "symbols = data['symbol'].unique().tolist()\n",
    "X = []\n",
    "Y = []\n",
    "for sym in symbols:\n",
    "    sym_data = scaler.transform(data.loc[data.symbol==sym].drop([\"symbol\"], axis=1))\n",
    "    for i in range(len(sym_data)-1):\n",
    "        X.append(sym_data[i])\n",
    "        Y.append(1 if (sym_data[i][1]<sym_data[i+1][1]) else 0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=seed)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "\n",
    "train_dataset = train_dataset.shuffle(60000).batch(batch_size)\n",
    "test_dataset = test_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "model = tf.keras.Sequential(tf.keras.layers.Dense(1, input_shape=(input_shape,), activation='sigmoid'))\n",
    "optimizer = tf.keras.optimizers.Adam(lr)\n",
    "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, optimizer, x_train, y_train):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(x_train, training=True)\n",
    "        loss = loss_object(y_train, predictions)\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(y_train, predictions)\n",
    "\n",
    "def test_step(model, x_test, y_test):\n",
    "    predictions = model(x_test)\n",
    "    loss = loss_object(y_test, predictions)\n",
    "\n",
    "    test_loss(loss)\n",
    "    test_accuracy(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.7098779082298279, Accuracy: 48.92850875854492, Test Loss: 0.7050596475601196, Test Accuracy: 49.03877258300781\n",
      "Epoch 2, Loss: 0.7006615400314331, Accuracy: 48.59392166137695, Test Loss: 0.6981518268585205, Test Accuracy: 48.72164535522461\n",
      "Epoch 3, Loss: 0.6957471966743469, Accuracy: 48.46595001220703, Test Loss: 0.6951598525047302, Test Accuracy: 48.7048225402832\n",
      "Epoch 4, Loss: 0.6939400434494019, Accuracy: 48.46490478515625, Test Loss: 0.6939343810081482, Test Accuracy: 48.71603775024414\n",
      "Epoch 5, Loss: 0.6932833790779114, Accuracy: 48.44289016723633, Test Loss: 0.6934661269187927, Test Accuracy: 48.71274185180664\n",
      "Epoch 6, Loss: 0.693047285079956, Accuracy: 48.4443244934082, Test Loss: 0.6932674050331116, Test Accuracy: 48.71274185180664\n",
      "Epoch 7, Loss: 0.6929551362991333, Accuracy: 48.440513610839844, Test Loss: 0.693193256855011, Test Accuracy: 48.71274185180664\n",
      "Epoch 8, Loss: 0.6928817629814148, Accuracy: 48.44166946411133, Test Loss: 0.6931477189064026, Test Accuracy: 48.71274185180664\n"
     ]
    }
   ],
   "source": [
    "test_total_profits = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    for (x_train, y_train) in train_dataset:\n",
    "        train_step(model, optimizer, x_train, y_train)\n",
    "    with train_summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', train_loss.result(), step=epoch)\n",
    "        tf.summary.scalar('accuracy', train_accuracy.result(), step=epoch)\n",
    "\n",
    "    for (x_test, y_test) in test_dataset:\n",
    "        test_step(model, x_test, y_test)\n",
    "    with test_summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', test_loss.result(), step=epoch)\n",
    "        tf.summary.scalar('accuracy', test_accuracy.result(), step=epoch)\n",
    "\n",
    "    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "    print (template.format(epoch+1,\n",
    "            train_loss.result(), \n",
    "            train_accuracy.result()*100,\n",
    "            test_loss.result(), \n",
    "            test_accuracy.result()*100))\n",
    "\n",
    "    # Reset metrics every epoch\n",
    "    train_loss.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.065688364, 'open'),\n",
       " (-0.25414512, 'close'),\n",
       " (0.098018594, 'low'),\n",
       " (-0.053747613, 'high'),\n",
       " (-0.0031226682, 'volume'),\n",
       " (0.2693475, 'Accounts Payable'),\n",
       " (0.036650922, 'Accounts Receivable'),\n",
       " (-0.079571575, \"Add'l income/expense items\"),\n",
       " (-0.120506, 'After Tax ROE'),\n",
       " (0.12006131, 'Capital Expenditures'),\n",
       " (0.08369791, 'Capital Surplus'),\n",
       " (-0.08065148, 'Cash Ratio'),\n",
       " (-0.08879869, 'Cash and Cash Equivalents'),\n",
       " (0.050556034, 'Changes in Inventories'),\n",
       " (-0.05422868, 'Common Stocks'),\n",
       " (0.14120719, 'Cost of Revenue'),\n",
       " (-0.16494855, 'Current Ratio'),\n",
       " (-0.044657417, 'Deferred Asset Charges'),\n",
       " (-0.070604466, 'Deferred Liability Charges'),\n",
       " (0.0065494184, 'Depreciation'),\n",
       " (0.18256819, 'Earnings Before Interest and Tax'),\n",
       " (0.14028029, 'Earnings Before Tax'),\n",
       " (0.090178944, 'Effect of Exchange Rate'),\n",
       " (-0.105616115, 'Equity Earnings/Loss Unconsolidated Subsidiary'),\n",
       " (-0.20446442, 'Fixed Assets'),\n",
       " (-0.0069143446, 'Goodwill'),\n",
       " (-0.008647252, 'Gross Margin'),\n",
       " (0.1365483, 'Gross Profit'),\n",
       " (0.07682944, 'Income Tax'),\n",
       " (0.16664517, 'Intangible Assets'),\n",
       " (-0.15639922, 'Interest Expense'),\n",
       " (-0.055705827, 'Inventory'),\n",
       " (0.06631114, 'Investments'),\n",
       " (0.17435192, 'Liabilities'),\n",
       " (0.13324766, 'Long-Term Debt'),\n",
       " (0.21468751, 'Long-Term Investments'),\n",
       " (-0.015633725, 'Minority Interest'),\n",
       " (0.04921593, 'Misc. Stocks'),\n",
       " (-0.021158103, 'Net Borrowings'),\n",
       " (0.062278755, 'Net Cash Flow'),\n",
       " (0.13208446, 'Net Cash Flow-Operating'),\n",
       " (-0.03808883, 'Net Cash Flows-Financing'),\n",
       " (-0.032754637, 'Net Cash Flows-Investing'),\n",
       " (-0.010861436, 'Net Income'),\n",
       " (0.06488298, 'Net Income Adjustments'),\n",
       " (-0.0305002, 'Net Income Applicable to Common Shareholders'),\n",
       " (-0.10467003, 'Net Income-Cont. Operations'),\n",
       " (0.10794015, 'Net Receivables'),\n",
       " (-0.22338659, 'Non-Recurring Items'),\n",
       " (-0.06222209, 'Operating Income'),\n",
       " (0.016123889, 'Operating Margin'),\n",
       " (-0.10888063, 'Other Assets'),\n",
       " (-0.080474906, 'Other Current Assets'),\n",
       " (-0.045849107, 'Other Current Liabilities'),\n",
       " (0.102848865, 'Other Equity'),\n",
       " (0.042820003, 'Other Financing Activities'),\n",
       " (0.123563334, 'Other Investing Activities'),\n",
       " (0.18342869, 'Other Liabilities'),\n",
       " (-0.041674953, 'Other Operating Activities'),\n",
       " (-0.19214903, 'Other Operating Items'),\n",
       " (-0.1721293, 'Pre-Tax Margin'),\n",
       " (0.118742734, 'Pre-Tax ROE'),\n",
       " (0.15984623, 'Profit Margin'),\n",
       " (0.21938097, 'Quick Ratio'),\n",
       " (-0.011489655, 'Research and Development'),\n",
       " (0.159055, 'Retained Earnings'),\n",
       " (-0.1645442, 'Sale and Purchase of Stock'),\n",
       " (-0.09314056, 'Sales, General and Admin.'),\n",
       " (-0.00580505, 'Short-Term Debt / Current Portion of Long-Term Debt'),\n",
       " (0.15629661, 'Short-Term Investments'),\n",
       " (0.06318133, 'Total Assets'),\n",
       " (-0.32693917, 'Total Current Assets'),\n",
       " (0.04123702, 'Total Current Liabilities'),\n",
       " (-0.060960438, 'Total Equity'),\n",
       " (-0.26202697, 'Total Liabilities'),\n",
       " (-0.16724336, 'Total Liabilities & Equity'),\n",
       " (-0.14681666, 'Total Revenue'),\n",
       " (0.23290014, 'Treasury Stock'),\n",
       " (0.19295752, 'Earnings Per Share'),\n",
       " (-0.13835157, 'Estimated Shares Outstanding')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = data.columns[1:].tolist()\n",
    "weights = model.layers[0].get_weights()\n",
    "[(weights[0][i][0], columns[i]) for i in range(len(columns))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 1\n",
    "run_lenght = 10\n",
    "initial_money = 100\n",
    "train_test_ratio = 0.2\n",
    "env = Stocks_env(data, window_size, run_lenght, batch_size=batch_size, train_test_ratio = train_test_ratio,\n",
    "                 test_seed=seed, initial_money=initial_money)\n",
    "batch_size  = len(env.get_test_symbols())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_env(record_days=False):\n",
    "    state = env.reset(training=False, batch_size=batch_size, run_lenght=run_lenght, initial_money=initial_money)\n",
    "    state = np.reshape(state, (batch_size, len(columns)))\n",
    "    done = False\n",
    "    operation_array = []\n",
    "    days_array = []\n",
    "    rewards_array = []\n",
    "    total_profit = np.zeros(batch_size)\n",
    "    while not done:\n",
    "        actions = []\n",
    "        for result in model(state):\n",
    "            buy = 1 if result>0 else 0 \n",
    "            sell = 1 if result<0 else 0\n",
    "            actions += [[buy, sell]]\n",
    "        next_state, reward, done, operations, day, profit = env.step(actions)\n",
    "        state = next_state\n",
    "        if record_days:\n",
    "            operation_array.append(np.array(operations))\n",
    "            days_array.append(np.array(day))\n",
    "            rewards_array.append(np.array(reward))\n",
    "        mean_test_reward(np.array(reward))\n",
    "        total_profit += profit\n",
    "    total_profit = total_profit/initial_money\n",
    "    return operation_array, days_array, rewards_array, total_profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "save_directory = 'results/test-all/'\n",
    "date = datetime.now().strftime(\"%Y_%m_%d-%H:%M:%S\")\n",
    "identifier = \"logreg-\" + date\n",
    "test_summary_writer = tf.summary.create_file_writer('results/summaries/test/' + identifier)\n",
    "mean_test_reward = tf.keras.metrics.Mean(name='mean_test_reward')\n",
    "\n",
    "repeat = 100\n",
    "\n",
    "test_total_profits = []\n",
    "\n",
    "for i in range(repeat):\n",
    "\n",
    "    print(i)\n",
    "    operation_array, days_array, rewards_array, test_total_profit = test_env(record_days=True)\n",
    "    test_total_profits.append(test_total_profit)\n",
    "\n",
    "    with test_summary_writer.as_default():\n",
    "        tf.summary.scalar('mean_test_reward', mean_test_reward.result(), step=i)\n",
    "\n",
    "    # serialize weights to HDF5\n",
    "    if not os.path.exists(save_directory):\n",
    "        os.makedirs(save_directory)\n",
    "    if not os.path.exists(save_directory+'operations/'):\n",
    "        os.makedirs(save_directory+'operations/')\n",
    "    if not os.path.exists(save_directory+'endingdays/'):\n",
    "        os.makedirs(save_directory+'endingdays/')\n",
    "    if not os.path.exists(save_directory+'rewards/'):\n",
    "        os.makedirs(save_directory+'rewards/')\n",
    "    if not os.path.exists(save_directory+'profits/'):\n",
    "        os.makedirs(save_directory+'profits/')\n",
    "    pd.DataFrame(operation_array).to_csv(save_directory+\"operations/{}-iteration{}.csv\".format(identifier, i), \n",
    "                                         header=env.get_current_symbols(), index=None)\n",
    "    pd.DataFrame(days_array).to_csv(save_directory+\"endingdays/{}-iteration{}.csv\".format(identifier, i), \n",
    "                                         header=env.get_current_symbols(), index=None)\n",
    "    pd.DataFrame(rewards_array).to_csv(save_directory+\"rewards/{}-iteration{}.csv\".format(identifier, i), \n",
    "                                         header=env.get_current_symbols(), index=None)\n",
    "    pd.DataFrame(test_total_profits).to_csv(save_directory+\"profits/{}.csv\".format(identifier),\n",
    "                                            index=None)\n",
    "    mean_test_reward.reset_states()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
