{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if not './' in sys.path:\n",
    "    sys.path.append('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "import os\n",
    "\n",
    "from envs.stocks_env_multiaction import Stocks_env\n",
    "from datasets import nyse\n",
    "from models.lstm_selfattention_embedding import ActorCritic\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "[LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n",
      "WARNING:tensorflow:From <ipython-input-3-94fe1c854373>:14: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "              tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "        \n",
    "print(tf.config.experimental.list_logical_devices('GPU'))\n",
    "tf.test.is_gpu_available()\n",
    "\n",
    "# set up policy used in mixed precision\n",
    "# from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "# policy = mixed_precision.Policy('mixed_float16')\n",
    "# mixed_precision.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = nyse.load_data('../data/')\n",
    "data, tokenized_industry, vocabulary_size = nyse.load_data_with_industry('../data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper params:\n",
    "lr               = 1e-5\n",
    "run_lenght       = 30\n",
    "window_size      = 5\n",
    "hidden_dim       = 512\n",
    "num_filters      = 128\n",
    "lstm_units       = 1024\n",
    "num_blocks       = 1\n",
    "embedding_out    = 6\n",
    "in_lstm_units    = 16\n",
    "initial_money    = 100\n",
    "test_seed        = None\n",
    "batch_size       = len(np.unique(data.symbol))\n",
    "\n",
    "# log\n",
    "tested_model = 'model-stonks-2021_02_25-07:36:05'\n",
    "save_directory = 'results/test-all/'\n",
    "models_directory = 'results/models/'\n",
    "identifier = \"test-2021_02_25-07:36:05\"\n",
    "test_summary_writer = tf.summary.create_file_writer('results/summaries/test/' + identifier)\n",
    "mean_test_reward = tf.keras.metrics.Mean(name='mean_test_reward')\n",
    "mean_test_daily_change = tf.keras.metrics.Mean(name='mean_test_daily_change')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize env\n",
    "env = Stocks_env(data, batch_size, window_size, run_lenght, train_test_ratio=1,\n",
    "                 tokenized_industry=tokenized_industry, test_seed=test_seed, initial_money=initial_money)\n",
    "num_inputs  = env.get_observation_space()\n",
    "num_policies = env.get_action_space()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "model = ActorCritic(num_policies = num_policies, hidden_dim=hidden_dim, num_filters=num_filters, \n",
    "                    lstm_units=lstm_units, text_lenght=tokenized_industry.shape[1], \n",
    "                    vocabulary_size=vocabulary_size, embedding_out=embedding_out, in_lstm_units = in_lstm_units)\n",
    "optimizer = tf.keras.optimizers.Adam(lr)\n",
    "state = env.reset(training=False)\n",
    "model(state[0], state[1])\n",
    "model.load_weights(models_directory + tested_model + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_env(record_days=False):\n",
    "    state = env.reset(training=False, batch_size=batch_size, run_lenght=run_lenght, initial_money=initial_money)\n",
    "    done = False\n",
    "    operation_array = []\n",
    "    days_array = []\n",
    "    rewards_array = []\n",
    "    total_profit = np.zeros(batch_size)\n",
    "    while not done:\n",
    "        _, dist = model(state[0], state[1])\n",
    "        next_state, reward, done, operations, day, daily_change, profit = env.step(dist.sample())\n",
    "        state = next_state\n",
    "        if record_days:\n",
    "            operation_array.append(np.array(operations))\n",
    "            days_array.append(np.array(day))\n",
    "            rewards_array.append(np.array(reward))\n",
    "        mean_test_reward(np.array(reward))\n",
    "        mean_test_daily_change(np.array(daily_change))\n",
    "        total_profit += profit\n",
    "    total_profit = total_profit/initial_money\n",
    "    return operation_array, days_array, rewards_array, total_profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "repeat = 100\n",
    "\n",
    "test_total_profits = []\n",
    "\n",
    "for i in range(repeat):\n",
    "\n",
    "    print(i)\n",
    "    operation_array, days_array, rewards_array, test_total_profit = test_env(record_days=True)\n",
    "    test_total_profits.append(test_total_profit)\n",
    "\n",
    "    with test_summary_writer.as_default():\n",
    "        tf.summary.scalar('mean_test_reward', mean_test_reward.result(), step=i)\n",
    "\n",
    "    # serialize weights to HDF5\n",
    "    if not os.path.exists(save_directory):\n",
    "        os.makedirs(save_directory)\n",
    "    if not os.path.exists(save_directory+'operations/'):\n",
    "        os.makedirs(save_directory+'operations/')\n",
    "    if not os.path.exists(save_directory+'endingdays/'):\n",
    "        os.makedirs(save_directory+'endingdays/')\n",
    "    if not os.path.exists(save_directory+'rewards/'):\n",
    "        os.makedirs(save_directory+'rewards/')\n",
    "    if not os.path.exists(save_directory+'profits/'):\n",
    "        os.makedirs(save_directory+'profits/')\n",
    "    pd.DataFrame(operation_array).to_csv(save_directory+\"operations/{}-iteration{}.csv\".format(identifier, i), \n",
    "                                         header=env.get_current_symbols(), index=None)\n",
    "    pd.DataFrame(days_array).to_csv(save_directory+\"endingdays/{}-iteration{}.csv\".format(identifier, i), \n",
    "                                         header=env.get_current_symbols(), index=None)\n",
    "    pd.DataFrame(rewards_array).to_csv(save_directory+\"rewards/{}-iteration{}.csv\".format(identifier, i), \n",
    "                                         header=env.get_current_symbols(), index=None)\n",
    "    pd.DataFrame(test_total_profits).to_csv(save_directory+\"profits/{}.csv\".format(identifier),\n",
    "                                            index=None)\n",
    "    mean_test_reward.reset_states()\n",
    "    mean_test_daily_change.reset_states()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
